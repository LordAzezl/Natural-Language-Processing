{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "IMDB = '/NLP/Dataset/IMDB Dataset.csv'\n",
    "IMDB = pd.read_csv(IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_text(review):\n",
    "    # Replace <br> HTML tags with space\n",
    "    review = re.sub(r'<br\\s*/?>', ' ', review)\n",
    "    # Retain only alphabetic characters and spaces\n",
    "    review = re.sub(r'[^A-Za-z\\s]', '', review)\n",
    "    return review.lower().strip()  # Convert to lowercase and remove leading/trailing spaces\n",
    "\n",
    "# Applying the cleaning function to reviews\n",
    "IMDB['review'] = IMDB['review'].map(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production  the filming tec...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one of the other reviewers has mentioned that ...        NaN\n",
       "1  a wonderful little production  the filming tec...        NaN\n",
       "2  i thought this was a wonderful way to spend ti...        NaN\n",
       "3  basically theres a family where a little boy j...        NaN\n",
       "4  petter matteis love in the time of money is a ...        NaN"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply binary conversion for sentiment column\n",
    "def convert_sentiment(value):\n",
    "    return 1 if value == 'positive' else 0\n",
    "\n",
    "IMDB['sentiment'] = IMDB['sentiment'].apply(convert_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenizing and padding sequences\n",
    "vocab_limit = 20000\n",
    "max_sequence_length = 200\n",
    "text_tokenizer = Tokenizer(num_words=vocab_limit)\n",
    "\n",
    "# Fitting tokenizer on the IMDB reviews\n",
    "text_tokenizer.fit_on_texts(IMDB['review'])\n",
    "\n",
    "# Converting text to sequences\n",
    "tokenized_sequences = text_tokenizer.texts_to_sequences(IMDB['review'])\n",
    "\n",
    "# Padding the sequences to ensure uniform length\n",
    "X = pad_sequences(tokenized_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Extracting sentiment values as labels\n",
    "y = IMDB['sentiment'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GloVe embeddings into a dictionary\n",
    "embedding_dim = 100\n",
    "glove_file_path = '/NLP/glove.6B.100d.txt'\n",
    "word_embeddings = {}\n",
    "\n",
    "# Reading the GloVe file and storing the word vectors\n",
    "with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "    for entry in f:\n",
    "        split_entry = entry.split()\n",
    "        token = split_entry[0]\n",
    "        embedding_vector = np.array(split_entry[1:], dtype='float32')\n",
    "        word_embeddings[token] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index['the'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "num_words = min(vocab_size, len(word_index) + 1)\n",
    "embedding_matrix_glove = np.zeros((num_words, embedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 100)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    if i < vocab_size:\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix_glove[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
       "         0.82779998,  0.27061999],\n",
       "       [-0.071953  ,  0.23127   ,  0.023731  , ..., -0.71894997,\n",
       "         0.86894   ,  0.19539   ],\n",
       "       ...,\n",
       "       [ 0.0035074 , -0.14286   ,  0.80261999, ..., -0.58814001,\n",
       "         0.31889999,  0.012209  ],\n",
       "       [ 0.20203   , -0.25244001, -0.12557   , ..., -0.16885   ,\n",
       "        -0.99378997,  0.32501   ],\n",
       "       [ 0.097328  ,  0.37051001, -0.34889001, ...,  0.037943  ,\n",
       "         0.27794001,  0.68112999]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "# RNN Model\n",
    "rnn_model = Sequential([\n",
    "    Embedding(input_dim=num_words,\n",
    "              output_dim=embedding_size,\n",
    "              embeddings_initializer=Constant(embedding_matrix_glove),\n",
    "              input_length=sequence_len,\n",
    "              trainable=False),  # Pre-trained embeddings are frozen\n",
    "    SimpleRNN(10, return_sequences=True),\n",
    "    SimpleRNN(5, return_sequences=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.2009 - val_accuracy: 1.0000 - val_loss: 0.0639\n",
      "Epoch 2/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0540 - val_accuracy: 1.0000 - val_loss: 0.0334\n",
      "Epoch 3/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0206\n",
      "Epoch 4/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
      "Epoch 5/5\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 1.0000 - val_loss: 0.0101\n"
     ]
    }
   ],
   "source": [
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = (rnn_model.predict(X_val) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Embedding Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production  the filming tec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one of the other reviewers has mentioned that ...          0\n",
       "1  a wonderful little production  the filming tec...          0\n",
       "2  i thought this was a wonderful way to spend ti...          0\n",
       "3  basically theres a family where a little boy j...          0\n",
       "4  petter matteis love in the time of money is a ...          0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = IMDB['review'].values\n",
    "labels = IMDB['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize reviews\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "# Tokenize all reviews\n",
    "tokenized_reviews = [tokenize(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter([word for review in tokenized_reviews for word in review])\n",
    "\n",
    "# Create word to index mapping\n",
    "word2idx = {word: i+2 for i, word in enumerate(vocab)}\n",
    "word2idx['<PAD>'] = 0\n",
    "word2idx['<UNK>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((len(word2idx), embedding_dim))\n",
    "\n",
    "for word, idx in word2idx.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IMDBTextDataset(Dataset):\n",
    "    def __init__(self, reviews, sentiments, vocab_index, max_sequence_length=200):\n",
    "        self.texts = reviews\n",
    "        self.sentiments = sentiments\n",
    "        self.vocab_index = vocab_index\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        sentiment = self.sentiments[index]\n",
    "        \n",
    "        # Convert words to indices, pad if necessary\n",
    "        word_indices = [self.vocab_index.get(word, self.vocab_index['<UNK>']) for word in text]\n",
    "        if len(word_indices) > self.max_sequence_length:\n",
    "            word_indices = word_indices[:self.max_sequence_length]\n",
    "        else:\n",
    "            word_indices += [self.vocab_index['<PAD>']] * (self.max_sequence_length - len(word_indices))\n",
    "        \n",
    "        return torch.tensor(word_indices), torch.tensor(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_texts, test_texts, train_sentiments, test_sentiments = train_test_split(\n",
    "    tokenized_reviews, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create dataset instances\n",
    "train_data = IMDBTextDataset(train_texts, train_sentiments, word2idx)\n",
    "test_data = IMDBTextDataset(test_texts, test_sentiments, word2idx)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SentimentLSTMNet(nn.Module):\n",
    "    def __init__(self, embed_matrix, lstm_hidden_size, output_size, num_lstm_layers, dropout_rate):\n",
    "        super(SentimentLSTMNet, self).__init__()\n",
    "        \n",
    "        vocab_size, embedding_dim = embed_matrix.shape\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_layer.weight = nn.Parameter(torch.tensor(embed_matrix, dtype=torch.float32))\n",
    "        self.embedding_layer.weight.requires_grad = False  # Freeze pre-trained GloVe embeddings\n",
    "        \n",
    "        self.lstm_layer = nn.LSTM(embedding_dim, lstm_hidden_size, num_layers=num_lstm_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc_layer = nn.Linear(lstm_hidden_size, output_size)\n",
    "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embedded_words = self.embedding_layer(inputs)\n",
    "        lstm_output, (hidden_state, cell_state) = self.lstm_layer(embedded_words)\n",
    "        final_output = self.fc_layer(self.dropout_layer(hidden_state[-1]))\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_hidden_units = 128\n",
    "num_output_classes = 1\n",
    "num_lstm_layers = 2\n",
    "dropout_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentiment_model = SentimentLSTMNet(embedding_matrix, lstm_hidden_units, num_output_classes, num_lstm_layers, dropout_prob).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer_function = optim.Adam(sentiment_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_model(model, data_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for text_batch, sentiment_batch in data_loader:\n",
    "            text_batch, sentiment_batch = text_batch.to(device), sentiment_batch.to(device).float()\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(text_batch).squeeze(1)\n",
    "            loss = criterion(predictions, sentiment_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(data_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.009956482363387477\n",
      "Epoch 2/5, Loss: 3.709256580332294e-05\n",
      "Epoch 3/5, Loss: 1.5574855865270365e-05\n",
      "Epoch 4/5, Loss: 8.478736374672735e-06\n",
      "Epoch 5/5, Loss: 5.0284756598557575e-06\n"
     ]
    }
   ],
   "source": [
    "train_lstm_model(sentiment_model, train_data_loader, loss_function, optimizer_function, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        for text_batch, sentiment_batch in data_loader:\n",
    "            text_batch, sentiment_batch = text_batch.to(device), sentiment_batch.to(device).float()\n",
    "            predictions = model(text_batch).squeeze(1)\n",
    "            predicted_labels = torch.round(torch.sigmoid(predictions))\n",
    "            correct_predictions += (predicted_labels == sentiment_batch).sum().item()\n",
    "            total_samples += sentiment_batch.size(0)\n",
    "        \n",
    "        accuracy = correct_predictions / total_samples * 100\n",
    "        print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_lstm_model(sentiment_model, test_data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
