{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc1359fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a331814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "wv_pretrained = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd58cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377322435379028),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134939193726),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411403656006)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find most similar words\n",
    "wv_pretrained.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb217a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mango', 0.6317152380943298),\n",
       " ('bananas', 0.6275610327720642),\n",
       " ('mangoes', 0.6114541888237),\n",
       " ('citrus_fruit', 0.59001624584198),\n",
       " ('fruits', 0.5772441625595093),\n",
       " ('avocados', 0.5595457553863525),\n",
       " ('Fruit', 0.5569567084312439),\n",
       " ('pineapples', 0.5541747808456421),\n",
       " ('Cavendish_bananas', 0.55269855260849),\n",
       " ('melon', 0.5473435521125793)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_pretrained.most_similar(positive=[\"fruit\", \"banana\"], negative=[\"red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "549f0181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Parisian', 0.6453418731689453),\n",
       " ('French', 0.6274688839912415),\n",
       " ('Hopital_Europeen_Georges_Pompidou', 0.5950257778167725),\n",
       " ('Avignon', 0.5637456774711609),\n",
       " ('Grigny_south', 0.5540268421173096),\n",
       " ('Spyker_D##_Peking', 0.5531150698661804),\n",
       " ('de_France', 0.5530701875686646),\n",
       " ('Saint_Honoré', 0.5517325401306152),\n",
       " ('Picardie', 0.5504419207572937),\n",
       " ('Nanterre_west', 0.548758864402771)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_pretrained.most_similar(positive=[\"Paris\", \"France\"], negative=[\"Germany\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44e0cc26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lady', 0.5354641675949097),\n",
       " ('person', 0.5296355485916138),\n",
       " ('Woman', 0.513024628162384),\n",
       " ('men', 0.4956325590610504),\n",
       " ('policewoman', 0.4909152388572693),\n",
       " ('WOMAN', 0.4802447259426117),\n",
       " ('motorist', 0.47880926728248596),\n",
       " ('women', 0.47408223152160645),\n",
       " ('teenage_girl', 0.4722822904586792),\n",
       " ('businesswoman', 0.469870001077652)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_pretrained.most_similar(positive=[\"man\", \"woman\"], negative=[\"boy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc8f621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('contentment', 0.5909623503684998),\n",
       " ('satisfaction', 0.5197392106056213),\n",
       " ('happier', 0.47888270020484924),\n",
       " ('contented', 0.4626934230327606),\n",
       " ('joy', 0.45936357975006104),\n",
       " ('Happiness', 0.45890146493911743),\n",
       " ('Adobe_CS2_Premium', 0.45625054836273193),\n",
       " ('satisfied', 0.44240081310272217),\n",
       " ('prosocial_spending', 0.43790724873542786),\n",
       " ('marital_bliss', 0.4179442822933197)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_pretrained.most_similar(positive=[\"happy\", \"happiness\"], negative=[\"sad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef9ccf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('walked', 0.6889522671699524),\n",
       " ('walks', 0.6313304901123047),\n",
       " ('Walking', 0.5557611584663391),\n",
       " ('stroll', 0.5340489149093628),\n",
       " ('strolls', 0.5130729675292969),\n",
       " ('wander', 0.4973868429660797),\n",
       " ('strolling', 0.48373162746429443),\n",
       " ('saunter', 0.48220333456993103),\n",
       " ('trudging', 0.46994322538375854),\n",
       " ('striding', 0.4681999683380127)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_pretrained.most_similar(positive=[\"walking\", \"walk\"], negative=[\"swimming\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c38454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r'D:\\school stuff\\SEM 7\\movie_reviews.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea783f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe998c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f690f500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive    25000\n",
      "negative    25000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbb72856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "766650da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning\n",
    "df['cleaned_text'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09c8bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['sentiment'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c4c30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f468981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of sentences for Word2Vec training\n",
    "sentences = X_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ec9be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Skip-gram model\n",
    "skipgram_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, sg=1)\n",
    "skipgram_model.save(\"skipgram_model.model\")\n",
    "with open('skipgram_model.pkl', 'wb') as f:\n",
    "    pickle.dump(skipgram_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b8084c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CBOW model\n",
    "cbow_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, sg=0)\n",
    "cbow_model.save(\"cbow_model.model\")\n",
    "with open('cbow_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cbow_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "588a83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained Word2Vec model\n",
    "pretrained_model = wv_pretrained\n",
    "with open('pretrained_word2vec_model.pkl', 'wb') as f:\n",
    "    pickle.dump(pretrained_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2e23a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize using custom Word2Vec models\n",
    "def get_word2vec_vectors(model, text, is_pretrained=False):\n",
    "    if is_pretrained:\n",
    "        vectors = [model[word] for word in text if word in model]\n",
    "    else:\n",
    "        vectors = [model.wv[word] for word in text if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "778fd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test sets for each model\n",
    "X_train_skipgram = np.array([get_word2vec_vectors(skipgram_model, text) for text in X_train])\n",
    "X_test_skipgram = np.array([get_word2vec_vectors(skipgram_model, text) for text in X_test])\n",
    "\n",
    "X_train_cbow = np.array([get_word2vec_vectors(cbow_model, text) for text in X_train])\n",
    "X_test_cbow = np.array([get_word2vec_vectors(cbow_model, text) for text in X_test])\n",
    "\n",
    "X_train_pretrained = np.array([get_word2vec_vectors(wv_pretrained, text, is_pretrained=True) for text in X_train])\n",
    "X_test_pretrained = np.array([get_word2vec_vectors(wv_pretrained, text, is_pretrained=True) for text in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "63aba878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifiers\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return accuracy, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8763cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip-gram model performance\n",
    "skipgram_accuracy, skipgram_report = train_and_evaluate(X_train_skipgram, X_test_skipgram, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e83da7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBOW model performance\n",
    "cbow_accuracy, cbow_report = train_and_evaluate(X_train_cbow, X_test_cbow, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff0a8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained Word2Vec model performance\n",
    "pretrained_accuracy, pretrained_report = train_and_evaluate(X_train_pretrained, X_test_pretrained, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f2cd81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "0            Skip-gram    0.8510\n",
      "1                 CBOW    0.8265\n",
      "2  Pretrained Word2Vec    0.8044\n"
     ]
    }
   ],
   "source": [
    "# Create a table of results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Skip-gram', 'CBOW', 'Pretrained Word2Vec'],\n",
    "    'Accuracy': [skipgram_accuracy, cbow_accuracy, pretrained_accuracy]\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28f59b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained classifiers\n",
    "with open('skipgram_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(skipgram_model, f)\n",
    "\n",
    "with open('cbow_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(cbow_model, f)\n",
    "\n",
    "with open('pretrained_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(pretrained_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
